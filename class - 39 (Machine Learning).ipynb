{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fe6796",
   "metadata": {},
   "source": [
    "# ENSEMBLE METHOD---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b48fa8eb",
   "metadata": {},
   "source": [
    "Snsemble method is those method which are going to work in segregation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83480d48",
   "metadata": {},
   "source": [
    "Ensemble methods are techniques that aim at improving the accuracy of results in models by combining multiple models instead of using a single model. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "31445420",
   "metadata": {},
   "source": [
    "Bagging (Paralled method) = different models and this model bydefult is decisiontree classifier \n",
    "\n",
    "and there are 100 models which are going to learn entair datasets indivisibly and the end the mean accuracy will be the final accuracy\n",
    "\n",
    "Pre defined algorithem - \n",
    "RandomForest -RandomForest is used by when the huge of datasets \n",
    "\n",
    "\n",
    "\n",
    "Boosting (Sequential method ) = datasets will be going to learn by model and than this model intput will be boosting at the 2nd model and than final output willbe coming here\n",
    "\n",
    "Predefined algorithem - \n",
    "Gradient boosting - \n",
    "Ada Boosting - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aaa181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892afb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e62fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e68bb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris data sets\n",
    "\n",
    "iris=load_iris()\n",
    "\n",
    "#print(iris)\n",
    "x=iris.data[:,:4]\n",
    "y=iris.target\n",
    "\n",
    "\n",
    "# train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a184b17",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87bfa1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "# RandomForestClassifier(100).......Default\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "predrf=rf.predict(x_test)\n",
    "print(accuracy_score(y_test,predrf))\n",
    "print(confusion_matrix(y_test,predrf))\n",
    "print(classification_report(y_test,predrf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe160b7a",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98d05bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), *, n_estimators=50, learning_rate=1.0\n",
    "\n",
    "ad=AdaBoostClassifier()\n",
    "\n",
    "ad.fit(x_train,y_train)\n",
    "ad_pred=ad.predict(x_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8fd45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ad=AdaBoostClassifier(n_estimators=50)\n",
    "\n",
    "ad.fit(x_train,y_train)\n",
    "ad_pred=ad.predict(x_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1471f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "[[ 0 10  0]\n",
      " [ 0  9  0]\n",
      " [ 0 11  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.30      1.00      0.46         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.10      0.33      0.15        30\n",
      "weighted avg       0.09      0.30      0.14        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import Support victor Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "# create AdaBoostClassifier object\n",
    "ad=AdaBoostClassifier(n_estimators=50, base_estimator=svc,algorithm='SAMME')\n",
    "ad.fit(x_train,y_train)\n",
    "ad_pred=ad.predict(x_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5060fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')\n",
    "# create AdaBoostClassifier object\n",
    "ad=AdaBoostClassifier(n_estimators=50, base_estimator=svc,algorithm='SAMME')\n",
    "ad.fit(x_train,y_train)\n",
    "ad_pred=ad.predict(x_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f32141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')\n",
    "# create AdaBoostClassifier object\n",
    "ad=AdaBoostClassifier(n_estimators=50, base_estimator=svc,algorithm='SAMME')\n",
    "ad.fit(x_train,y_train)\n",
    "ad_pred=ad.predict(x_test)\n",
    "print(accuracy_score(y_test,ad_pred))\n",
    "print(confusion_matrix(y_test,ad_pred))\n",
    "print(classification_report(y_test,ad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06464a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gd=GradientBoostingClassifier()\n",
    "gd.fit(x_train,y_train)\n",
    "gd_pred=gd.predict(x_test)\n",
    "print(accuracy_score(y_test,gd_pred))\n",
    "print(confusion_matrix(y_test,gd_pred))\n",
    "print(classification_report(y_test,gd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054375f",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85d7af1e",
   "metadata": {},
   "source": [
    "voting classifier will work with hetrogeanous dataset,\n",
    "\n",
    "hetrogeanous dataset means different deffernt typs of model,we can take deffernt defferent types of model for hetrogeanous sets in voting classifier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe9c4085",
   "metadata": {},
   "source": [
    "there are two types of Voting Classifier\n",
    "\n",
    "hard voting - hard voting and soft voting. Hard voting entails picking the prediction with the highest number of votes\n",
    "soft wvoting - whereas soft voting entails combining the probabilities of each prediction in each model and picking the prediction with the highest total probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8366b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3880f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group / ensemble of models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimator=[]\n",
    "estimator.append(('LR',KNeighborsClassifier()))\n",
    "estimator.append(('SVC',SVC(gamma='auto',probability=True)))\n",
    "estimator.append(('DTC',DecisionTreeClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f720614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR', KNeighborsClassifier()),\n",
       " ('SVC', SVC(gamma='auto', probability=True)),\n",
       " ('DTC', DecisionTreeClassifier())]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82581097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "hard voting score 1\n"
     ]
    }
   ],
   "source": [
    "# voting classifier with hard voting\n",
    "\n",
    "vot_hard = VotingClassifier(estimators=estimator,voting=\"hard\")\n",
    "vot_hard.fit(x_train,y_train)\n",
    "y_pred=vot_soft.predict(x_test)\n",
    "\n",
    "print(y_pred)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print('hard voting score %d'% score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e6009bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "soft voting score 1\n"
     ]
    }
   ],
   "source": [
    "# voting classifier with soft voting\n",
    "\n",
    "vot_soft = VotingClassifier(estimators = estimator,voting = \"soft\")\n",
    "vot_soft.fit(x_train,y_train)\n",
    "y_pred = vot_soft.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print('soft voting score %d'% score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700dc98",
   "metadata": {},
   "source": [
    "# Ensemble Over there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5560410",
   "metadata": {},
   "source": [
    "# Pipe Line"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09a36914",
   "metadata": {},
   "source": [
    "A machine learning pipeline is a way to codify and automate the workflow it takes to produce a machine learning model. Machine learning pipelines consist of multiple sequential steps that do everything from data extraction and preprocessing to model training and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5f37a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96270f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x,y = make_classification(random_state=0)\n",
    "\n",
    "#x_train,x_test,y_train,y_test=train_test_split()\n",
    "\n",
    "pipe=Pipeline([('scaler',StandardScaler()),('svc',SVC())])\n",
    "pipe.fit(x_train,y_train)\n",
    "Pipeline(steps=[('scaler',StandardScaler()),('svc',SVC())])\n",
    "pipe.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969a29d",
   "metadata": {},
   "source": [
    "# Gradient Decscent Algorithm - it is used to reduce the error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "182799ac",
   "metadata": {},
   "source": [
    "Types of Gradient Descent\n",
    "\n",
    "STOCASTIC GRADIENT DESCENT : - \n",
    "    \n",
    "    \n",
    "SGD is simple yet very efficent aproach to fitting linear classifier and regressors under convex loss functions such as (linear) Support victor machines and Logistics regression\n",
    "\n",
    "it is used to reduce down the learning rate in minimum error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a73b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor: 0.504684 (0.244393)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the datasets\n",
    "X=load_boston()\n",
    "data=pd.DataFrame(X.data,columns=X.feature_names)\n",
    "Y=X.target\n",
    "\n",
    "#Creating a model\n",
    "pipe =[]\n",
    "pipe.append(('SC',StandardScaler()))\n",
    "pipe.append(('PCA',PCA(n_components=8)))\n",
    "pipe.append(('SGD',SGDRegressor(alpha=0.1,learning_rate='optimal',max_iter=400,penalty='l2')))\n",
    "model=Pipeline(pipe)\n",
    "\n",
    "# cross validation score\n",
    "cv_results=cross_val_score(model,data,Y,cv=5)\n",
    "msg = \"%s: %f (%f)\" % ('SGDRegressor',cv_results.mean(), cv_results.std())\n",
    "print(msg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c361c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier: 0.746667 (0.100222)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "X=load_iris()\n",
    "data=pd.DataFrame(X.data,columns=X.feature_names)\n",
    "Y=X.target\n",
    "\n",
    "# Creating a Model\n",
    "model=SGDClassifier()\n",
    "\n",
    "# cross validation score\n",
    "\n",
    "cv_results=cross_val_score(model,data,Y,cv=5)\n",
    "msg = \"%s: %f (%f)\" % ('SGDClassifier',cv_results.mean(), cv_results.std())\n",
    "print(msg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a75b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
